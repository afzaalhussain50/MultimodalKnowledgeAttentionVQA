{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from math import log\n",
    "import dgl\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from bisect import bisect\n",
    "from util.vocabulary import Vocabulary\n",
    "from util.checkpointing import CheckpointManager, load_checkpoint\n",
    "from model.model_okvqa import CMGCNnet\n",
    "from model.okvqa_train_dataset import OkvqaTrainDataset\n",
    "from model.okvqa_test_dataset import OkvqaTestDataset\n",
    "from model.fvqa_train_dataset import FvqaTrainDataset\n",
    "from model.fvqa_test_dataset import FvqaTestDataset\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model = TheModelClass(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def cal_acc(answers, preds):\n",
    "    all_num = len(preds)\n",
    "    acc_num_1 = 0\n",
    "\n",
    "    for i, answer_id in enumerate(answers):\n",
    "        pred = preds[i]  # (num_nodes)\n",
    "        try:\n",
    "\n",
    "            _, idx_1 = torch.topk(pred, k=1)\n",
    "\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        else:\n",
    "            if idx_1.item() == answer_id:\n",
    "                acc_num_1 = acc_num_1 + 1\n",
    "\n",
    "    return acc_num_1 / all_num\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    res = {}\n",
    "    qid_list = []\n",
    "    question_list = []\n",
    "    question_length_list = []\n",
    "    img_features_list = []\n",
    "    img_relations_list = []\n",
    "\n",
    "    fact_num_nodes_list = []\n",
    "    facts_node_features_list = []\n",
    "    facts_e1ids_list = []\n",
    "    facts_e2ids_list = []\n",
    "    facts_answer_list = []\n",
    "    facts_answer_id_list = []\n",
    "\n",
    "    semantic_num_nodes_list = []\n",
    "    semantic_node_features_list = []\n",
    "    semantic_e1ids_list = []\n",
    "    semantic_e2ids_list = []\n",
    "    semantic_edge_features_list = []\n",
    "    semantic_num_nodes_list = []\n",
    "\n",
    "    for item in batch:\n",
    "        # question\n",
    "        qid = item['id']\n",
    "        qid_list.append(qid)\n",
    "\n",
    "        question = item['question']\n",
    "        question_list.append(question)\n",
    "\n",
    "        question_length = item['question_length']\n",
    "        question_length_list.append(question_length)\n",
    "\n",
    "        # image\n",
    "        img_features = item['img_features']\n",
    "        img_features_list.append(img_features)\n",
    "\n",
    "        img_relations = item['img_relations']\n",
    "        img_relations_list.append(img_relations)\n",
    "\n",
    "        # fact\n",
    "        fact_num_nodes = item['facts_num_nodes']\n",
    "        fact_num_nodes_list.append(fact_num_nodes)\n",
    "\n",
    "        facts_node_features = item['facts_node_features']\n",
    "        facts_node_features_list.append(facts_node_features)\n",
    "\n",
    "        facts_e1ids = item['facts_e1ids']\n",
    "        facts_e1ids_list.append(facts_e1ids)\n",
    "\n",
    "        facts_e2ids = item['facts_e2ids']\n",
    "        facts_e2ids_list.append(facts_e2ids)\n",
    "\n",
    "        facts_answer = item['facts_answer']\n",
    "        facts_answer_list.append(facts_answer)\n",
    "\n",
    "        facts_answer_id = item['facts_answer_id']\n",
    "        facts_answer_id_list.append(facts_answer_id)\n",
    "\n",
    "        # semantic\n",
    "        semantic_num_nodes = item['semantic_num_nodes']\n",
    "        semantic_num_nodes_list.append(semantic_num_nodes)\n",
    "\n",
    "        semantic_node_features = item['semantic_node_features']\n",
    "        semantic_node_features_list.append(semantic_node_features)\n",
    "\n",
    "        semantic_e1ids = item['semantic_e1ids']\n",
    "        semantic_e1ids_list.append(semantic_e1ids)\n",
    "\n",
    "        semantic_e2ids = item['semantic_e2ids']\n",
    "        semantic_e2ids_list.append(semantic_e2ids)\n",
    "\n",
    "        semantic_edge_features = item['semantic_edge_features']\n",
    "        semantic_edge_features_list.append(semantic_edge_features)\n",
    "\n",
    "    res['id_list'] = qid_list\n",
    "    res['question_list'] = question_list\n",
    "    res['question_length_list'] = question_length_list\n",
    "    res['features_list'] = img_features_list\n",
    "    res['img_relations_list'] = img_relations_list\n",
    "    res['facts_num_nodes_list'] = fact_num_nodes_list\n",
    "    res['facts_node_features_list'] = facts_node_features_list\n",
    "    res['facts_e1ids_list'] = facts_e1ids_list\n",
    "    res['facts_e2ids_list'] = facts_e2ids_list\n",
    "    res['facts_answer_list'] = facts_answer_list\n",
    "    res['facts_answer_id_list'] = facts_answer_id_list\n",
    "    res['semantic_node_features_list'] = semantic_node_features_list\n",
    "    res['semantic_e1ids_list'] = semantic_e1ids_list\n",
    "    res['semantic_e2ids_list'] = semantic_e2ids_list\n",
    "    res['semantic_edge_features_list'] = semantic_edge_features_list\n",
    "    res['semantic_num_nodes_list'] = semantic_num_nodes_list\n",
    "    return res\n",
    "\n",
    "\n",
    "def cal_batch_loss(fact_batch_graph, batch, device, pos_weight, neg_weight):\n",
    "    answers = batch['facts_answer_list']\n",
    "    fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "    batch_loss = torch.tensor(0).to(device)\n",
    "\n",
    "    for i, fact_graph in enumerate(fact_graphs):\n",
    "        pred = fact_graph.ndata['h']  # (n,2)\n",
    "        answer = answers[i].long().to(device)\n",
    "        weight = torch.FloatTensor([0.9, 0.1]).to(device)\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fn(pred, answer)\n",
    "        batch_loss = batch_loss + loss\n",
    "\n",
    "    return batch_loss / len(answers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='okvqa', type=None, choices=None, help='dataset that model training on', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--cpu-workers\", type=int, default=0, help=\"Number of CPU workers for dataloader.\")\n",
    "parser.add_argument(\"--overfit\", action=\"store_true\", help=\"Whether to validate on val split after every epoch.\")\n",
    "parser.add_argument(\"--validate\", action=\"store_true\", help=\"Whether to validate on val split after every epoch.\")\n",
    "parser.add_argument(\"--gpu-ids\", nargs=\"+\", type=int, default=0, help=\"List of ids of GPUs to use.\")\n",
    "parser.add_argument(\"--dataset\", default=\"okvqa\", help=\"dataset that model training on\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mucko\\lib\\site-packages\\ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "config_path = 'model/config_okvqa.yml'\n",
    "config = yaml.load(open(config_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# glove 相关\n",
    "print('Loading glove...')\n",
    "glovevocabulary = Vocabulary(config[\"dataset\"][\"word_counts_json\"], min_count=config[\"dataset\"][\"vocab_min_count\"])\n",
    "glove = np.load(config['dataset']['glove_vec_path'])\n",
    "glove = torch.Tensor(glove)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = CMGCNnet(config,\n",
    "                 que_vocabulary=glovevocabulary,\n",
    "                 glove=glove,\n",
    "                 device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OKVQATestDataset...\n",
      "loading dataset_opendomain_q_raw20.json\n",
      "loading image_feature.npz\n",
      "loading semantic_graph_feature20.npz\n",
      "loading fact_graph_feature20.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.load_state_dict(torch.load('exp_okvqa/checkpoint_8.pth'))\n",
    "\n",
    "model_state, optimizer = load_checkpoint('exp_okvqa/checkpoint_8.pth')\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "answers = []  # [batch_answers,...]\n",
    "preds = []  # [batch_preds,...]\n",
    "\n",
    "print('Loading OKVQATestDataset...')\n",
    "val_dataset = OkvqaTestDataset(config, overfit=args.overfit, in_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                            batch_size=config['solver']['batch_size'],\n",
    "                            num_workers=args.cpu_workers,\n",
    "                            shuffle=True,\n",
    "                            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Validation:\")\n",
    "for i, batch in enumerate(tqdm(val_dataloader)):\n",
    "    with torch.no_grad():\n",
    "        fact_batch_graph = model(batch)\n",
    "    batch_loss = cal_batch_loss(fact_batch_graph,\n",
    "                                batch,\n",
    "                                device,\n",
    "                                neg_weight=0.1,\n",
    "                                pos_weight=0.9)\n",
    "\n",
    "    fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "    for i, fact_graph in enumerate(fact_graphs):\n",
    "        pred = fact_graph.ndata['h'].squeeze()  # (num_nodes,1)\n",
    "        preds.append(pred[:, 1])  # [(num_nodes,)]\n",
    "        answers.append(batch['facts_answer_id_list'][i])\n",
    "\n",
    "acc_1 = cal_acc(answers, preds)\n",
    "\n",
    "print(\"acc@1={:.2%} \".format(acc_1))\n",
    "\n",
    "abc = 123\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}