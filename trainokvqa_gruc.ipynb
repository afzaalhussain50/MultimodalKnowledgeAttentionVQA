{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from math import log\n",
    "import dgl\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from bisect import bisect\n",
    "from util.vocabulary import Vocabulary\n",
    "from util.checkpointing import CheckpointManager, load_checkpoint\n",
    "from model.model_okvqa_gruc import CMGCNnet\n",
    "from model.okvqa_train_dataset_gruc import OkvqaTrainDataset\n",
    "from model.okvqa_test_dataset import OkvqaTestDataset\n",
    "from model.fvqa_train_dataset import FvqaTrainDataset\n",
    "from model.fvqa_test_dataset import FvqaTestDataset\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cal_batch_loss(fact_batch_graph, batch, device, pos_weight, neg_weight):\n",
    "    answers = batch['facts_answer_list']\n",
    "    fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "    batch_loss = torch.tensor(0).to(device)\n",
    "\n",
    "    for i, fact_graph in enumerate(fact_graphs):\n",
    "        pred = fact_graph.ndata['h']  # (n,2)\n",
    "        answer = answers[i].long().to(device)\n",
    "        weight = torch.FloatTensor([0.9, 0.1]).to(device)\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fn(pred, answer)\n",
    "        batch_loss = batch_loss + loss\n",
    "\n",
    "    return batch_loss / len(answers)\n",
    "\n",
    "\n",
    "def cal_batch_loss2(fact_batch_graph, batch, device, pos_weight, neg_weight):\n",
    "    answers = batch['facts_answer_list']\n",
    "    fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "    batch_loss = torch.tensor(0).to(device)\n",
    "\n",
    "    for i, fact_graph in enumerate(fact_graphs):\n",
    "        class_weight = torch.FloatTensor([neg_weight, pos_weight])\n",
    "        pred = fact_graph.ndata['h'].view(1, -1)  # (n,1)\n",
    "        answer = torch.FloatTensor(answers[i]).view(1, -1).to(device)\n",
    "        pred = pred.squeeze()\n",
    "        answer = answer.squeeze()\n",
    "        weight = class_weight[answer.long()].to(device)\n",
    "        loss_fn = torch.nn.BCELoss(weight=weight)\n",
    "        loss = loss_fn(pred, answer)\n",
    "        batch_loss = batch_loss + loss\n",
    "\n",
    "    return batch_loss / len(answers)\n",
    "\n",
    "\n",
    "def focal_loss(fact_batch_graph, batch, device, alpha=0.5, gamma=2):\n",
    "    answers = batch['facts_answer_list']\n",
    "    fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "    batch_loss = torch.tensor(0).float().to(device)\n",
    "\n",
    "    for i, fact_graph in enumerate(fact_graphs):\n",
    "        pred = fact_graph.ndata['h'].squeeze()\n",
    "        target = torch.FloatTensor(answers[i]).to(device).squeeze()\n",
    "        loss = -1 * alpha * ((1 - pred) ** gamma) * target * torch.log(pred) - (1 - alpha) * (target ** gamma) * (\n",
    "            1 - pred) * torch.log(1 - pred)\n",
    "        batch_loss = batch_loss+loss.mean()\n",
    "    return batch_loss/len(answers)\n",
    "\n",
    "\n",
    "def cal_acc(answers, preds):\n",
    "    all_num = len(preds)\n",
    "    acc_num_1 = 0\n",
    "\n",
    "\n",
    "\n",
    "    for i, answer_id in enumerate(answers):\n",
    "        pred = preds[i]  # (num_nodes)\n",
    "        try:\n",
    "\n",
    "            _, idx_1 = torch.topk(pred, k=1)\n",
    "\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "        else:\n",
    "            if idx_1.item() == answer_id:\n",
    "                acc_num_1 = acc_num_1 + 1\n",
    "\n",
    "    return acc_num_1 / all_num\n",
    "\n",
    "def collate_fn(batch):\n",
    "    res = {}\n",
    "    qid_list = []\n",
    "    question_list = []\n",
    "    question_length_list = []\n",
    "    img_features_list = []\n",
    "    img_relations_list = []\n",
    "\n",
    "    fact_num_nodes_list = []\n",
    "    facts_node_features_list = []\n",
    "    facts_e1ids_list = []\n",
    "    facts_e2ids_list = []\n",
    "    facts_answer_list = []\n",
    "    facts_answer_id_list = []\n",
    "\n",
    "    semantic_num_nodes_list = []\n",
    "    semantic_node_features_list = []\n",
    "    semantic_e1ids_list = []\n",
    "    semantic_e2ids_list = []\n",
    "    semantic_edge_features_list = []\n",
    "    semantic_num_nodes_list = []\n",
    "\n",
    "    for item in batch:\n",
    "        # question\n",
    "        qid = item['id']\n",
    "        qid_list.append(qid)\n",
    "\n",
    "        question = item['question']\n",
    "        question_list.append(question)\n",
    "\n",
    "        question_length = item['question_length']\n",
    "        question_length_list.append(question_length)\n",
    "\n",
    "        # image\n",
    "        img_features = item['img_features']\n",
    "        img_features_list.append(img_features)\n",
    "\n",
    "        img_relations = item['img_relations']\n",
    "        img_relations_list.append(img_relations)\n",
    "\n",
    "        # fact\n",
    "        fact_num_nodes = item['facts_num_nodes']\n",
    "        fact_num_nodes_list.append(fact_num_nodes)\n",
    "\n",
    "        facts_node_features = item['facts_node_features']\n",
    "        facts_node_features_list.append(facts_node_features)\n",
    "\n",
    "        facts_e1ids = item['facts_e1ids']\n",
    "        facts_e1ids_list.append(facts_e1ids)\n",
    "\n",
    "        facts_e2ids = item['facts_e2ids']\n",
    "        facts_e2ids_list.append(facts_e2ids)\n",
    "\n",
    "        facts_answer = item['facts_answer']\n",
    "        facts_answer_list.append(facts_answer)\n",
    "\n",
    "        facts_answer_id = item['facts_answer_id']\n",
    "        facts_answer_id_list.append(facts_answer_id)\n",
    "\n",
    "        # semantic\n",
    "        semantic_num_nodes = item['semantic_num_nodes']\n",
    "        semantic_num_nodes_list.append(semantic_num_nodes)\n",
    "\n",
    "        semantic_node_features = item['semantic_node_features']\n",
    "        semantic_node_features_list.append(semantic_node_features)\n",
    "\n",
    "        semantic_e1ids = item['semantic_e1ids']\n",
    "        semantic_e1ids_list.append(semantic_e1ids)\n",
    "\n",
    "        semantic_e2ids = item['semantic_e2ids']\n",
    "        semantic_e2ids_list.append(semantic_e2ids)\n",
    "\n",
    "        semantic_edge_features = item['semantic_edge_features']\n",
    "        semantic_edge_features_list.append(semantic_edge_features)\n",
    "\n",
    "    res['id_list'] = qid_list\n",
    "    res['question_list'] = question_list\n",
    "    res['question_length_list'] = question_length_list\n",
    "    res['features_list'] = img_features_list\n",
    "    res['img_relations_list'] = img_relations_list\n",
    "    res['facts_num_nodes_list'] = fact_num_nodes_list\n",
    "    res['facts_node_features_list'] = facts_node_features_list\n",
    "    res['facts_e1ids_list'] = facts_e1ids_list\n",
    "    res['facts_e2ids_list'] = facts_e2ids_list\n",
    "    res['facts_answer_list'] = facts_answer_list\n",
    "    res['facts_answer_id_list'] = facts_answer_id_list\n",
    "    res['semantic_node_features_list'] = semantic_node_features_list\n",
    "    res['semantic_e1ids_list'] = semantic_e1ids_list\n",
    "    res['semantic_e2ids_list'] = semantic_e2ids_list\n",
    "    res['semantic_edge_features_list'] = semantic_edge_features_list\n",
    "    res['semantic_num_nodes_list'] = semantic_num_nodes_list\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--dataset'], dest='dataset', nargs=None, const=None, default='okvqa', type=None, choices=None, help='dataset that model training on', metavar=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 配置文件\n",
    "parser.add_argument(\"--config-yml\", default=\"model/config_okvqa_gruc.yml\", help=\"Path to a config file listing reader, model and solver parameters.\")\n",
    "# 创建dataloader时使用多少个进程\n",
    "parser.add_argument(\"--cpu-workers\", type=int, default=0, help=\"Number of CPU workers for dataloader.\")\n",
    "# 快照存储的位置\n",
    "parser.add_argument(\"--save-dirpath\", default=\"exp_okvqa_gruc\", help=\"Path of directory to create checkpoint directory and save checkpoints.\")\n",
    "\n",
    "parser.add_argument(\"--overfit\", action=\"store_true\", help=\"Whether to validate on val split after every epoch.\")\n",
    "parser.add_argument(\"--validate\", action=\"store_true\", help=\"Whether to validate on val split after every epoch.\")\n",
    "parser.add_argument(\"--gpu-ids\", nargs=\"+\", type=int, default=0, help=\"List of ids of GPUs to use.\")\n",
    "parser.add_argument(\"--dataset\", default=\"okvqa\", help=\"dataset that model training on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set mannual seed\n",
    "torch.manual_seed(10)\n",
    "torch.cuda.manual_seed(10)\n",
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parser.add_argument('-f')\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\mucko\\lib\\site-packages\\ipykernel_launcher.py:8: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================================\n",
    "#                                 (2) Input config file\n",
    "# ============================================================================================\n",
    "if(args.dataset == 'fvqa'):\n",
    "    config_path = 'model/config_fvqa.yml'\n",
    "elif(args.dataset == 'okvqa'):\n",
    "    config_path = 'model/config_okvqa_gruc.yml'\n",
    "config = yaml.load(open(config_path))\n",
    "\n",
    "if isinstance(args.gpu_ids, int):\n",
    "    args.gpu_ids = [args.gpu_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_yml          : model/config_okvqa_gruc.yml\n",
      "cpu_workers         : 0\n",
      "save_dirpath        : exp_okvqa_gruc\n",
      "overfit             : False\n",
      "validate            : False\n",
      "gpu_ids             : [0]\n",
      "dataset             : okvqa\n",
      "f                   : C:\\Users\\afzaal\\AppData\\Roaming\\jupyter\\runtime\\kernel-699fac52-e1d4-487a-b7e8-a09e615735ce.json\n"
     ]
    }
   ],
   "source": [
    "# my changes in code comment orignal device and initize device from practice tutorial of pytorch\n",
    "# device = torch.device(\"cuda\", args.gpu_ids[0]) if args.gpu_ids[0] >= 0 else torch.device(\"cpu\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "for arg in vars(args):\n",
    "    print(\"{:<20}: {}\".format(arg, getattr(args, arg)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OKVQATrainDataset...\n",
      "loading dataset_opendomain_q_raw.json\n",
      "loading image_feature.npz\n",
      "loading semantic_graph_feature.npz\n",
      "loading fact_graph_feature.npz\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================================\n",
    "#                                  Setup Dataset, Dataloader\n",
    "# ============================================================================================\n",
    "if (args.dataset == 'okvqa'):\n",
    "    print('Loading OKVQATrainDataset...')\n",
    "    train_dataset = OkvqaTrainDataset(config, overfit=args.overfit, in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_dataset.sliced_data(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=config['solver']['batch_size'],\n",
    "                              num_workers=args.cpu_workers,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=collate_fn)\n",
    "\n",
    "if args.validate:\n",
    "    print('Loading OKVQATestDataset...')\n",
    "    val_dataset = OkvqaTestDataset(config, overfit=args.overfit, in_memory=True)\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                batch_size=config['solver']['batch_size'],\n",
    "                                num_workers=args.cpu_workers,\n",
    "                                shuffle=True,\n",
    "                                collate_fn=collate_fn)\n",
    "\n",
    "if (args.dataset == 'fvqa'):\n",
    "    print('Loading FVQATrainDataset...')\n",
    "    train_dataset = FvqaTrainDataset(config, overfit=args.overfit, in_memory=True)\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=config['solver']['batch_size'],\n",
    "                                  num_workers=args.cpu_workers,\n",
    "                                  shuffle=True,\n",
    "                                  collate_fn=collate_fn)\n",
    "\n",
    "    if args.validate:\n",
    "        print('Loading FVQATestDataset...')\n",
    "        val_dataset = FvqaTestDataset(config, overfit=args.overfit, in_memory=True)\n",
    "        val_dataloader = DataLoader(val_dataset,\n",
    "                                    batch_size=config['solver']['batch_size'],\n",
    "                                    num_workers=args.cpu_workers,\n",
    "                                    shuffle=True,\n",
    "                                    collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove...\n"
     ]
    }
   ],
   "source": [
    "# glove 相关\n",
    "print('Loading glove...')\n",
    "glovevocabulary = Vocabulary(config[\"dataset\"][\"word_counts_json\"], min_count=config[\"dataset\"][\"vocab_min_count\"])\n",
    "glove = np.load(config['dataset']['glove_vec_path'])\n",
    "glove = torch.Tensor(glove)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model...\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================================\n",
    "#                                   Setup Model & mutil GPUs\n",
    "# ================================================================================================\n",
    "print('Building Model...')\n",
    "model = CMGCNnet(config,\n",
    "                 que_vocabulary=glovevocabulary,\n",
    "                 glove=glove,\n",
    "                 device=device)\n",
    "\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if -1 not in args.gpu_ids and len(args.gpu_ids) > 1:\n",
    "    model = nn.DataParallel(model, args.gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "iterations = len(train_dataset) // config[\"solver\"][\"batch_size\"] + 1\n",
    "\n",
    "def lr_lambda_fun(current_iteration: int) -> float:\n",
    "    \"\"\"Returns a learning rate multiplier.\n",
    "\n",
    "    Till `warmup_epochs`, learning rate linearly increases to `initial_lr`,\n",
    "    and then gets multiplied by `lr_gamma` every time a milestone is crossed.\n",
    "    \"\"\"\n",
    "    current_epoch = float(current_iteration) / iterations\n",
    "    if current_epoch <= config[\"solver\"][\"warmup_epochs\"]:\n",
    "        alpha = current_epoch / float(config[\"solver\"][\"warmup_epochs\"])\n",
    "        return config[\"solver\"][\"warmup_factor\"] * (1. - alpha) + alpha\n",
    "    else:\n",
    "        idx = bisect(config[\"solver\"][\"lr_milestones\"], current_epoch)\n",
    "        return pow(config[\"solver\"][\"lr_gamma\"], idx)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adamax(model.parameters(),\n",
    "                         lr=config[\"solver\"][\"initial_lr\"])\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda_fun)\n",
    "T = iterations * (config[\"solver\"][\"num_epochs\"] -\n",
    "                  config[\"solver\"][\"warmup_epochs\"] + 1)\n",
    "scheduler2 = lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, int(T), eta_min=config[\"solver\"][\"eta_min\"], last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ================================================================================================\n",
    "#                                Setup Before Traing Loop\n",
    "# ================================================================================================\n",
    "\n",
    "\n",
    "checkpoint_manager = CheckpointManager(model,\n",
    "                                       optimizer,\n",
    "                                       args.save_dirpath,\n",
    "                                       config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\mucko\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "100%|██████████| 4/4 [27:34<00:00, 413.69s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=6.25% \n",
      "\n",
      "Training for epoch 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [37:27<00:00, 561.85s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=3.12% \n",
      "\n",
      "Training for epoch 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:09:58<00:00, 1049.68s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=1.56% \n",
      "\n",
      "Training for epoch 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [2:29:11<00:00, 2237.95s/it]  \n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=1.56% \n",
      "\n",
      "Training for epoch 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:40:52<00:00, 1513.22s/it]  \n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=1.56% \n",
      "\n",
      "Training for epoch 5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [25:50<00:00, 387.74s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=0.00% \n",
      "\n",
      "Training for epoch 6:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [23:05<00:00, 346.35s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=1.56% \n",
      "\n",
      "Training for epoch 7:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [27:43<00:00, 415.99s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=3.12% \n",
      "\n",
      "Training for epoch 8:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [25:56<00:00, 389.14s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=1.56% \n",
      "\n",
      "Training for epoch 9:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [23:02<00:00, 345.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainacc@1=0.00% \n",
      "Train finished !!!\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "# ================================================================================================\n",
    "#                                    Traing Loop\n",
    "# ================================================================================================\n",
    "# Forever increasing counter keeping track of iterations completed (for tensorboard logging).\n",
    "global_iteration_step = start_epoch * iterations\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x=[]\n",
    "test_y = []\n",
    "best_test_acc=0\n",
    "best_epoch=0\n",
    "\n",
    "for epoch in range(start_epoch, config['solver']['num_epochs']):\n",
    "\n",
    "    print(f\"\\nTraining for epoch {epoch}:\")\n",
    "\n",
    "    train_answers = []\n",
    "    train_preds = []\n",
    "\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        fact_batch_graph = model(batch)\n",
    "        batch_loss = cal_batch_loss(fact_batch_graph,\n",
    "                                    batch,\n",
    "                                    device,\n",
    "                                    neg_weight=0.1,\n",
    "                                    pos_weight=0.9)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "        for i, fact_graph in enumerate(fact_graphs):\n",
    "            train_pred = fact_graph.ndata['h'].squeeze()  # (num_nodes,2)\n",
    "            train_preds.append(train_pred[:,1])  # [(num_nodes,)]\n",
    "            train_answers.append(batch['facts_answer_id_list'][i])\n",
    "\n",
    "\n",
    "        if global_iteration_step <= iterations * config[\"solver\"][\n",
    "                \"warmup_epochs\"]:\n",
    "            scheduler.step(global_iteration_step)\n",
    "        else:\n",
    "            global_iteration_step_in_2 = iterations * config[\"solver\"][\n",
    "                \"warmup_epochs\"] + 1 - global_iteration_step\n",
    "            scheduler2.step(int(global_iteration_step_in_2))\n",
    "\n",
    "        global_iteration_step = global_iteration_step + 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    #   ON EPOCH END  (checkpointing and validation)\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    checkpoint_manager.step()\n",
    "    train_acc_1 = cal_acc(train_answers, train_preds)\n",
    "\n",
    "    print(\"trainacc@1={:.2%} \".format(train_acc_1))\n",
    "\n",
    "\n",
    "    # Validate and report automatic metrics.\n",
    "    if args.validate:\n",
    "        model.eval()\n",
    "        answers = []  # [batch_answers,...]\n",
    "        preds = []  # [batch_preds,...]\n",
    "        print(f\"\\nValidation after epoch {epoch}:\")\n",
    "        for i, batch in enumerate(tqdm(val_dataloader)):\n",
    "            with torch.no_grad():\n",
    "                fact_batch_graph = model(batch)\n",
    "            batch_loss = cal_batch_loss(fact_batch_graph,\n",
    "                                        batch,\n",
    "                                        device,\n",
    "                                        neg_weight=0.1,\n",
    "                                        pos_weight=0.9)\n",
    "\n",
    "            fact_graphs = dgl.unbatch(fact_batch_graph)\n",
    "            for i, fact_graph in enumerate(fact_graphs):\n",
    "                pred = fact_graph.ndata['h'].squeeze()  # (num_nodes,1)\n",
    "                preds.append(pred[:,1])  # [(num_nodes,)]\n",
    "                answers.append(batch['facts_answer_id_list'][i])\n",
    "\n",
    "        acc_1 = cal_acc(answers, preds)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"acc@1={:.2%} \".\n",
    "              format(acc_1))\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        torch.cuda.empty_cache()\n",
    "print('Train finished !!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
